{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8289658,"sourceType":"datasetVersion","datasetId":4924185}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kareemakompf/audiotoquestionanswers?scriptVersionId=176611682\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-09T09:43:15.82586Z","iopub.execute_input":"2024-05-09T09:43:15.826479Z","iopub.status.idle":"2024-05-09T09:43:16.178041Z","shell.execute_reply.started":"2024-05-09T09:43:15.82645Z","shell.execute_reply":"2024-05-09T09:43:16.17713Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/primagenb/the-downsides-of-c-prime-reacts.mp3\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install accelerate\n!pip install -i https://pypi.org/simple/ bitsandbytes\n!pip install transformers[torch] datasets[audio]\n!pip install librosa \n!pip install -qU langchain-text-splitters\n!pip install langchain\n!pip install tiktoken\n!pip instal sentence-transformers\n!pip install faiss-gpu","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:43:17.804388Z","iopub.execute_input":"2024-05-09T09:43:17.804901Z","iopub.status.idle":"2024-05-09T09:45:13.248713Z","shell.execute_reply.started":"2024-05-09T09:43:17.804868Z","shell.execute_reply":"2024-05-09T09:45:13.247675Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nLooking in indexes: https://pypi.org/simple/\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.1\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: datasets[audio] in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.29.3)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets[audio]) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (3.9.1)\nRequirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.12.1)\nRequirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.10.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (3.0.1)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.11.4)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.4.0)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (5.1.1)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (0.58.1)\nRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.8.1)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (0.3.7)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (0.3)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.0.7)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[audio]) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[audio]) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[audio]) (2023.4)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.21)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa->datasets[audio]) (0.41.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa->datasets[audio]) (4.2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.16.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa->datasets[audio]) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\nRequirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (0.10.1)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa) (3.0.1)\nRequirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.26.4)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.11.4)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.4.0)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (5.1.1)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.58.1)\nRequirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.12.1)\nRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.8.1)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.3.7)\nRequirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (4.9.0)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.3)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.0.7)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.41.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa) (4.2.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa) (21.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa) (2.31.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pooch>=1.0->librosa) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.9.3 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting langchain\n  Downloading langchain-0.1.19-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\nCollecting langchain-community<0.1,>=0.0.38 (from langchain)\n  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.52)\nRequirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.1)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.56)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\nRequirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (23.2)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nDownloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: langchain-community, langchain\nSuccessfully installed langchain-0.1.19 langchain-community-0.0.38\nCollecting tiktoken\n  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\nDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tiktoken\nSuccessfully installed tiktoken-0.6.0\nERROR: unknown command \"instal\" - maybe you meant \"install\"\nCollecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline \nimport librosa \nimport torch \n\nprimagen, sr = librosa.load(os.path.join(dirname, filename), sr=16_000)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n\nwhisper = pipeline(\"automatic-speech-recognition\", device = device, \n                       model=\"openai/whisper-small\")\n\noutput = whisper(\n    primagen, \n    return_timestamps=True, \n    generate_kwargs = {\"task\": \"transcribe\"}, \n    chunk_length_s=30, \n)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:45:13.250894Z","iopub.execute_input":"2024-05-09T09:45:13.251221Z","iopub.status.idle":"2024-05-09T09:47:31.659427Z","shell.execute_reply.started":"2024-05-09T09:45:13.251189Z","shell.execute_reply":"2024-05-09T09:47:31.658615Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-05-09 09:45:18.361279: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-09 09:45:18.361370: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-09 09:45:18.485719: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6143419911d64aa1b929ad0e51a14346"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3590cb17715c408681ae8a2608cf6d64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c41d0ef2d1bf4c9db338008a7a0330ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97178b1bff284ef9a33c252d1195bf95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc462da213a64f608141e6d709223c66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a292018272064423b7b7e9acb45cc93b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc2a718c217c4da2bc013852dd56d992"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"047c424553804b39ada7ceb9737936e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e51fae5ddc004218858cb281d0c73c9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0de0a82e96424ae48b0f6ac57383d4f4"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab5069633c4d451aa4af7aa802e3ecd6"}},"metadata":{}}]},{"cell_type":"code","source":"import torch \nimport huggingface_hub as hubba \n\nfrom transformers import (\n    BitsAndBytesConfig, \n    AutoModelForCausalLM, \n    AutoTokenizer, \n) \n\nconfig = BitsAndBytesConfig(\n    load_in_4bit=True, \n    bnb_4bit_quant_type=\"nf4\", \n    bnb_4bit_compute_dtype=torch.float16, \n)\n\nhubba.login(token=\"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\")\n\ncheckpoint = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nmistral_tokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmistral = AutoModelForCausalLM.from_pretrained(\n    checkpoint, quantization_config=config, \n    device_map=device, \n)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:47:31.660519Z","iopub.execute_input":"2024-05-09T09:47:31.661168Z","iopub.status.idle":"2024-05-09T09:49:48.428343Z","shell.execute_reply.started":"2024-05-09T09:47:31.661141Z","shell.execute_reply":"2024-05-09T09:49:48.427351Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f7c80f09c2044b691627c009a2b7c95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc5609e347b74de2b63413bab6900a2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24087657f8b74fbd94ca8cfcf948a031"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04493c9cf128488e88d7519ad1237de6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"754688bcbabf43f9b851cb8e9550a6a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd1fc5f206cc4199a36f35a8ed032ece"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2456aa5d3094f13831bd661515a0eae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea35d4b5924543839f29dc2be253b6d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c53b420b5184121ab59cff50ff9a18b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a66e2557433425cba9d23e783880efc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f15836eac9846f493ad74b9653c6c48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e3550e12ae7401c9d1cb9f36a8ce483"}},"metadata":{}}]},{"cell_type":"code","source":"from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n\nmistral_pipe = pipeline(\"text-generation\", \n                       model=mistral, tokenizer=mistral_tokenizer,do_sample=True,\n                       max_new_tokens=1024, device_map=device, temperature=0.1)\n\nllm = HuggingFacePipeline(pipeline=mistral_pipe)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T12:08:49.849077Z","iopub.execute_input":"2024-05-09T12:08:49.849526Z","iopub.status.idle":"2024-05-09T12:08:49.856898Z","shell.execute_reply.started":"2024-05-09T12:08:49.849488Z","shell.execute_reply":"2024-05-09T12:08:49.855971Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"import langchain.prompts as pmt \n\nprompt_template = \"\"\"\nYou are an expert at creating questions based on coding materials and documentation.\nYour goal is to prepare a coder or programmer for their exam and coding tests.\nYou do this by asking questions about the text below:\n\n------------\n{text}\n------------\n\nCreate questions that will prepare the coders or programmers for their tests.\nMake sure not to lose any important information.\n\nQUESTIONS:\n\"\"\"\n\nPROMPT_QUESTIONS = pmt.PromptTemplate(\n    template=prompt_template, \n    input_variables=[\"text\"], \n)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:49:48.808675Z","iopub.execute_input":"2024-05-09T09:49:48.808942Z","iopub.status.idle":"2024-05-09T09:49:48.963622Z","shell.execute_reply.started":"2024-05-09T09:49:48.808919Z","shell.execute_reply":"2024-05-09T09:49:48.962748Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"refine_template = (\"\"\"\nYou are an expert at creating practice questions based on coding material and documentation.\nYour goal is to help a coder or programmer prepare for a coding test.\nWe have received some practice questions to a certain extent: {existing_answer}.\nWe have the option to refine the existing questions or add new ones.\n(only if necessary) with some more context below.\n------------\n{text}\n------------\n\nGiven the new context, refine the original questions in English.\nIf the context is not helpful, please provide the original questions.\nQUESTIONS:\n\"\"\"\n)\n\nREFINE_PROMPT_QUESTIONS = pmt.PromptTemplate(\n    input_variables=[\"existing_answer\", \"text\"],\n    template=refine_template,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:49:48.964809Z","iopub.execute_input":"2024-05-09T09:49:48.965077Z","iopub.status.idle":"2024-05-09T09:49:48.970177Z","shell.execute_reply.started":"2024-05-09T09:49:48.965053Z","shell.execute_reply":"2024-05-09T09:49:48.969126Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from langchain.chains.summarize import load_summarize_chain \n\nqna_chain = load_summarize_chain(llm = llm, \n                                chain_type = \"refine\", \n                                verbose = True, \n                                question_prompt=PROMPT_QUESTIONS, \n                                refine_prompt=REFINE_PROMPT_QUESTIONS)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:49:48.971133Z","iopub.execute_input":"2024-05-09T09:49:48.971402Z","iopub.status.idle":"2024-05-09T09:49:49.137755Z","shell.execute_reply.started":"2024-05-09T09:49:48.971375Z","shell.execute_reply":"2024-05-09T09:49:49.136987Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from langchain.text_splitter import TokenTextSplitter \nfrom langchain.docstore.document import Document \n\ncontent = output[\"text\"]\nsp = TokenTextSplitter(\n    chunk_overlap=40, \n    chunk_size=500, \n)\n\nanswers = sp.split_documents([Document(page_content=content)]) \nprint(\"Length of the answers %d\" % (len(answers)))","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:24:42.111875Z","iopub.execute_input":"2024-05-09T10:24:42.112613Z","iopub.status.idle":"2024-05-09T10:24:42.127193Z","shell.execute_reply.started":"2024-05-09T10:24:42.112581Z","shell.execute_reply":"2024-05-09T10:24:42.126317Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Length of the answers 11\n","output_type":"stream"}]},{"cell_type":"code","source":"import time \n\n\ndef run_for_different_split_counts(split_count): \n    sp = TokenTextSplitter(\n        chunk_overlap=0 if split_count <= 1 else 40, \n        chunk_size=20_000, \n    )\n    \n    answers = sp.split_documents([Document(page_content=content)]) \n    start = time.time()\n    output = qna_chain.run(answers)\n    seconds_passed = time.time() - start \n    \n    mins, second = divmod(seconds_passed, 60)\n    print(\"Time passed = %d mins %d seconds\" % (mins, second))\n    \n    return output \n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:18:49.658444Z","iopub.execute_input":"2024-05-09T10:18:49.658848Z","iopub.status.idle":"2024-05-09T10:18:49.665438Z","shell.execute_reply.started":"2024-05-09T10:18:49.658818Z","shell.execute_reply":"2024-05-09T10:18:49.664497Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"outputs = {}\nthree_splits = run_for_different_split_counts(split_count=3) \n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:21:04.35137Z","iopub.execute_input":"2024-05-09T10:21:04.352351Z","iopub.status.idle":"2024-05-09T10:21:40.083708Z","shell.execute_reply.started":"2024-05-09T10:21:04.352314Z","shell.execute_reply":"2024-05-09T10:21:40.082622Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n\n\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n\n\n\u001b[1m> Entering new LLMChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3m\nYou are an expert at creating questions based on coding materials and documentation.\nYour goal is to prepare a coder or programmer for their exam and coding tests.\nYou do this by asking questions about the text below:\n\n------------\n Alright, hey, C++ paper cuts. My current day job is now again a C++ roll hurts. I've been there, I recently had that happen like six months ago where I had to go back into C++ land for a while. Always is emotional bruising. And so I find myself yet again focusing on this blog post on the downsides of C++. Overall, I have found returning to active C++ dev to be exactly what I expected. I still have the skills and can still be effective in it, but now I have worked in a more modern programming language with less legacy cruft. The downsides of C++ sting more. Isn't that funny how that is? When I used to program for IE 7 and 8, IE 8 felt like a godsend, IE 7 felt horrifying. I think the rest is very, very obvious. As your environment and things become more modern, the feeling of pain becomes more real. There are so many features I miss from Rust, and not only the obvious safety features, just what I feel like, like the quote unquote safety features, just throw things in unique pointers and shared pointers and you have like 95% of what you got from the borrower. It's pretty nice. Or even primarily those, but also features that C++ could easily add, like some types called enums. I mean, you have, you have, you just have less convenient syntax for this. I mean, you still have that. You just have to make a little union type discriminator and boom, you got it, right? It's annoying, but I get it. I get it. Or first class support for tuples, but it doesn't quite have the same, it's definitely more dangerous. I will, I agree with you. It's more dangerous. It's more dangerous. Or first class support for tuples. Actually, I do like tuples. Tuples are glorious. Tuples are glorious until I use them. I swear every time I use a tuple, that dot zero and dot one syntax triggers me. It just triggers me. You know, you use a tuple because it's convenient and then after you get done using a tuple, you realize a struct is no different than a tuple, but it just has nicer names. And you go, why am I using that? Smart pointers are slow. This is true. Smart pointers are much slower. You're absolutely right. But so is the 1000 calls to dot clone in my Rust program. Okay. That also is very slow. That also is extremely slow. So it's like, which slow do we want to use? I don't know. Which slow would you like to use? I'm just saying, I'm just throwing it out there that I agree that having a compiler check, the unique pointer-ness of things is much better, but they are slower. Before I start getting into the paper cuts though, I want to address one of the primary defenses I've seen of C++, one that I've found particularly baffling. It goes something like this, C++ is a great programming language. Okay, that is baffling. I don't know anybody that says this. Like, I don't know anybody other than game devs that say this, okay, this is very strangeling. I don't know anybody that says this. Like, I don't know anybody other than game devs that say this. Okay, this is very strange take. What is this? Uh, the complaints are just from people who aren't up to it. Wow. If they were better programmers, they'd appreciate the C++ way of doing things and they wouldn't need their hand, they're handheld. Languages like Rust are not as helpful for such true professionals. The thing is, is you can make the identical argument for Rust. You'd start using rust and you make some bad design decisions early because you don't understand. And then you get into this point where your program becomes just unmaintainable without a full rewrite because you've just just done f**k the rust way of doing things. And people are like, well, if only you understood the idiomatic rust way of doing things and people are like well if only you understood the idiomatic rust way of doing things again it's all skill issues in all languages that argument is just a snooze fest it's always been a snooze fest it will always be a snooze fest and exists in every language it's just some make it some make it easier for you to go longer with your bad decisions and I think that that's a good thing okay Okay. I'm going to throw that out there. That's why I think go is so successful because you can go longer with a bad decision than you can in rust. Think about that for a second. Obviously the, uh, the phrasing is a bit of a parody, but I have seen this sort of attitude so many times. The most charitable view I can take of it is that a claim that C plus plus difficulty is a sign of its power and the natural cost of using a powerful I'm getting cancelled today boys! That's why we invented JavaScript, okay? You let the poor programmers use JavaScript. I'm getting canceled today, boys! And that good programmers don't benefit from making things easier. As somebody who has programmed C++ professionally for a majority of my career and who has taught a company internal classes and advanced C++, this is nonsense to me. I do know how to navigate many paper cuts and foot guns of C++ and I'm happy to do so when working on a C++ code base But experience as I am they still slow me down and Distract me taking focus away from the actual problems. I'm trying to solve and resulting in less maintainable code Yeah, I agree It sucks. I am no defender of C++ as As for the upside, I see very little any way in which C++ is more performant or more appropriate than Rust in terms of platform support legacy code bases optimization that are only available in specific compilers that often are that happen to not support Rust or other concerns irrelevant to the actual design of a programming language. I mean, there are and there are a lot of things that are very nice. You know, like when you're doing an array of structs and you're mutating and you're playing around, the amount of dancing and things you have to do in Rust are not as much as you have to do in C++. Granted, there's more foot guns, but there's things you can do in C++ that are just simpler problems to solve than you can do in Rust. While I'm proud of my C++ skills, I'm not too proud to appreciate the better technology can render them partially obsolete. And I'm not too proud to appreciate the having features that make it easier. In most cases, it's not a matter of programming languages doing more work for me, but of C++ creating unnecessary extra make work. Yeah, this is this is perfectly reasonable take often due to the decisions that made sense when they are made, but not long since stopped making sense. Don't get me started on header files. Yeah. Header files are a bit emotional for me. Me hates it. I do want you to know that I'm not ragging on Rust. It's just that I think that people with excellent C++ background are the worst Rust is the greatest people because you can almost virtually transfer all of your thoughts about C++ onto Rust. You know what I mean? The reason why header files suck is that it's called the module. Why do you need to define the same thing twice? What the hell are you doing defining things? Right? It makes, it literally makes no sense that you have a file that says, here is what my class looks like. And then you have another file that says, here's how you implement it. And yet it's for better compilation speed. You know, it's way cooler, single pass to create the header, second pass to create the thing, okay? It's called a two pass compiler, a three pass compiler, an N pass compiler, okay? They've been doing it for years. Somehow I'm able to state several functions that will be used and it doesn't have to compile the whole gosh darn thing to figure out what the hell I'm exporting, right? It doesn't have to be crazy. Yes, yes, yes. And Heterophile still has all the private members of the class inside. If I remember C++ is seven passes, which is crazy. I don't know if that's true, but that's wild, right? Single pass, you can get the shape of things, right? You can make these decisions. You don't need something to tell you what's already available. But I also want my programming programming language to be beginner friendly. I'm always going to work with other programmers who have a variety of skill sets and I would rather not have to clean up my colleagues mistakes or mistakes of earlier, more foolish versions of myself. If making a programming language more beginner friendly sacrifices power, then I agree that some programming language should not do it. Yep. I agree with that. Go. Go is a great language for this. But many, even most of C++ beginner, unfriendly and expert annoying features do not in fact make the language more powerful. So without further ado, here are the biggest paper cuts I've noticed in the past month of returning to C++ development. Love it. Love it. Const is not the default. Yeah, I do agree. I think that this is probably a better way of doing things I do like the idea of specifying mutations as opposed to specifying Specifying constantness. I think that's a better trade-off to make And remember with JavaScript you have to do a const const right there const pointers. They're not Constance so it's like a double one, you got to be extra careful. It is very easy to forget to mark a parameter const when it when it can be, you just forget to type the keyword. See, that's the thing is you never forget the type the mutation word, but you will always forget the type the const word. It's very, very true. This is especially true for this, which is an implicit parameter. There is no time when you are typing out this parameter explicitly, and therefore, it won't sit there looking funny without the appropriate modifiers. If C++ had the opposite default, which every value reference end pointer was const, unless explicitly declared mutable, then we'd be more likely to have every parameter declared correctly based on whether the function needs to mutated or not. If someone includes a mutable keyword, it would be because they know they need it. Yes, it acts. I do. I love this take, by the way. I think this is one of the big wins of Rust and other languages like OCaml. OCaml pioneered it for Rust. I think there's, I'm sure there's languages OCaml got it from. If they need it and forget it, the compiler arrow would remind them exactly, exactly. You want the compiler to tell you when you're wrong and this is beautiful. Now, you might not think this is important because you can just not use const and have functions with capabilities they don't need, but sometimes you have to take things by const in C++. If you take a parameter by non-const reference, the caller can only use L value to call your function. But if you take parameters by const reference, the caller can use l values or r values. So some functions in order to be used in natural ways must take their parameters by const reference. Once you have a const reference, you can only easily call functions with it and accept const references. And so if any of those functions forget to declare the parameter const, you have to include const cast or go to the function later and correctly accept const. Unless you think this is just a sloppy newbie error, note that many functions in the standard library had to be updated to take const iterator instead of the addition to iterator. When it was discovered correctly that they made sense with a const iterator. Functions like erase. It turns out that for functions like arrays, the collection is what has to be mutable, not the iterator, fact that maintainers of C++ library simply got wrong at first. That's pretty impressive to get that wrong, right? obligatory copying. Ah, sounds like are we talking about rust now? Is this rust? We're talking about rust in C++ for an object to be copyable is default. Okay, I do actually agree with this. I hate the fact that default is copy. There's something so effing emotional about the fact that when you take a vector and go const A equals this vector, const B equals A, you got yourself a copy. And there's something, it just, I agree. I agree, I've chased down, many a bug has been due to that one thing. Just hurts. If you don't want your object to be copyable and all of its fields are copyable, you often have to mark the copy constructor and copy assignment operator as equal delete. The default is for the compiler to write code for you. The code can, a code that can be incorrect. Yeah, yeah. If you do make your class move only, however, beware, because that means that there are situations where you can't use it in C++ 11. There is no ergonomic way to do a lambda capture by move, which is usually how I want to capture variables into a closure. No. Similarly, uh, the standard function expects the object it manages to be copyable and will fail if compile if your closure object is move only. This is going to be addressed in C++23, which should come out in 2033 with standard move only function, but in the meantime, I have been forced to write classes with a copy constructor that throws some sort of runtime logic exception, and even in C++ 23 copyable functions will be the default assumed situation. I love runtime exceptions for things that should not be runtime exceptions. Feels good using standard function, not like this. This is strange because most complicated objects, especially closures, are never and should never be copied. Generally copying a complicated data structure is a mistake, missing a and or a missing standard move, but it is a mistake that carries no warning with it and no visible sign in the code that a complex allocation heavy action is being undertaken. This is an early lesson to new C++ devs, don't pass non-primitive types by value, but it's possible for even advanced devs mess up from time to time and once it's in the codebase, it's easy to miss. Agree, I do, this bites me at least. Every time I start back up in C++, this bites me once. I mess up something, and it takes me like a good old fashioned GDB slash printf time to figure out what the hell did I do wrong. Buy reference parameter paper cuts. It is unergonomic to return multiple valuables by tuple and C++. Everybody loves standard tuple, come on. It can be done. But the calls to standard tie and to make tuple are long-winded and distracting, not to mention that you'll be writing unidiumatically, which is always bad for people who are reading and debugging your code. As a result, C++ often resorts to out parameters. Hmm, I love that C sharp so thoroughly loved and debugging your code. As a result, C++ often resorts to out parameters. Hmm, I love that C-sharp so thoroughly loved the idea of out parameters. You actually have an out keyword so that you can have out parameters in C-sharp. Chef's kiss on making hard code. In this as well as other situations, you end up taking a parameter by non-const reference, meaning the function is supposed to modify the parameter. The problem is, this is only marked in the function signature. If you have a function that takes a parameter by reference, the parameter looks the same as by value parameter at the call site, really? Let's see, return false on failure, modify size with actual size message, decreasing it if it contains more than one message. Message nice, dude, who abbreviates message like that? Okay, can we just time out this entire thing and just realize that this is, that I personally have some problems here? Okay, I got some problems going on here. Long before any of this is taking place, you know what I mean? That is cursed. It is cursed. Messagee. That's totally unhinged. Dude, it's totally unhinged. If you're reading the calling code quickly, it might look like the resize call is redundant, but it is not. Size is being modified by gotMessage. The only way to know that it is being modified is to look at the function signature, which is usually in another file. Yeah, I do agree. Again, specifying mutations are better than specifying constants. I think it's just generally accepted that it's true 100% of the time. Some people prefer outparameters in and outparameters to be passed by pointers for this very reason. I can purchase that. This is great. Or would be if pointers weren't nullable. What does a null pointer parameter mean in this context? It is going to be, is it going to trigger undefined behavior? What if you pass a pointer from a caller into it? People often forget to document what functions do with a null pointer. Options are just a great way to type system, specify this, and I love it. This can be addressed with non-nullable smart pointers, but very few programmers actually do this in practice. We kind of require ourselves at Netflix to do this. Smart pointers are great. In general, they're great. Yeah, they're a little bit slower, but you know, it's really slow debugging. That's really slow. Okay, that's emotionally slow. You know, it's even slower. The JavaScript we're running underneath. Okay, now that's emotionally slow. You know, it's you know, it's even slower the JavaScript were running underneath Okay, now that's the where the real slowness happens when something isn't the default It tends to not be used everywhere where appropriate the sustainable answer to this is changing the default not a heroic attempt to fight human nature fair obligatory sidegrip at least in non-owning Situations like this it is possible to write such a smart pointer. However, if you want to write the obvious companion, a non-nullable owning smart pointer, a companion version of standard unique pointer, then it cannot be done in a useful way, because such a pointer cannot then be movable. I don't quite understand that. This man has too much C++ power for me to understand. Method implementations can contradict. Ooh, this sounds exciting. Does always write the code correctly the first time. LOL, four head, five head, one head. I refuse to use smart pointers. Interesting. Really? You refuse to use them? Is it because of the atomic incrementer? I wish there was. Like one thing I say that Rust also does very well is not allowing non-atomic pointers to be pot to be passed between threads. I think that that's a really nice thing because that way you can have a literal plus one, a very simple, you know, smart pointer that RC to be passed around. And then you have the more costly arc when you need something, right? Smart pointers are awful. They're not that bad. Awful is a pretty intense word for it. They're not great. Okay, I prefer having my compiler be a smart pointer, but awful is a little intense. Yeah, if you have a C API, don't use a smart pointer. Anyways, all right, for many cases, for many classes, the default implementations are enough. And if possible, you should really rely on them or you should rely on them. Whether or not this is possible, depends on whether naively copying all the fields in a sensible way to copy the entire object, which is surprisingly easy to forget to consider, absolutely. But if you need a custom implementation of one of these, you are on the hook to write all of them. This is known as the rule of five. You have to write all of them, even though the correct behavior of the two assignment operators can be completely determined by the appropriate constructor combined with the destructor. The compiler could make default implementations of the assignment operators that refer to those other functions, and therefore would always be correct. But it does not. Implementing them correctly is tricky, requiring techniques like either explicitly protecting against self-assignment or swapping with buy-value parameter. In any case, there are boilerplate and yet another thing that can go wrong in a programming language that has many such things. Wait until your friend implements a template for you to solve this problem! Gosh! Conclusion. Unfortunately, I'm too well aware of why these decisions were made and it is exactly one reason. Compatibility with legacy code. C++ has no addition system, no way to deprecate core language features. If new addition of C++ was made, it would cease to be C++. Though I support the efforts of people to transition C++ to new syntax and clean some of this stuff up. Yeah, but Rust doesn't break backwards compatibility either. I think there's been one such case of a method being completely removed due to some gigantic security violation, but even with the additions, I don't think it removes anything, right? I don't think there's anything that says that it can't be undone. C++2, when? You should see C++23 before we talk about C++2, okay buddy? But Rust is a new language. Yeah, I know. Rust is a new language. Yeah, I know. Rust is a new language that's expanding exceptionally fast. Just wait for this article to exist with Rust. It's gonna happen, right? However, if you ignore backwards compatibility, it's gonna go back to OCaml. It always goes back to OCaml. Don't worry, it's coming back, the arc's happening. However, not not atomic reference counter, by the way. If you ignore backwards compatibility in the large existing code bases, none of these paper cuts make the programming language more powerful or better, just harder to use. I have seen good faith arguments in favor of human-maintained header files, surprising as, uh, that is to me, but I challenge my readers to tell me what is beneficial about C++'s design choice in these matters. I agree. You might find these things trivial, but these all slow programmers down while simultaneously annoying them. If you are experienced enough, your subconscious might be adept to navigate it, but imagine what your subconscious could do if it didn't have to. But how adept are you at seeing these mistakes in a code review from your junior colleagues? Impossible. If you are a rigorous reviewer, how much more time does it take? How adept are you at finding these issues quickly when a bug arises? These are great questions. Honestly, these are great things. Oh, Campbell sucks! You suck! Okay, you know what? We're not gonna have this. You know what? This is 1984, gonna happen right here. That message never existed. Get the hell out that message. What would be more effective? We'd be more effective, more efficient, and happier if these issues were resolved. Programming would be both enjoyable and faster to do. What's the downsides? The only upside is continuity with history. And while I can see the value in that, it is very limited value, with very limited scope. I agree. This is a great article. This is a great article on some of the C++ paper cuts. I really agree with the the the the the five one. That is the rule of five. It is just so painful and I've had it happen to me and it's just like it can go terribly wrong. Okay, hey C++ is cool, but man does it have some foot guns. The name is the Foot Gunnagen.\n------------\n\nCreate questions that will prepare the coders or programmers for their tests.\nMake sure not to lose any important information.\n\nQUESTIONS:\n\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\nTime passed = 0 mins 35 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"import re \n\ndef question_filter(content): \n    pattern = re.compile(r'\\d+\\. .*\\?+\\n')\n    return [ x.strip() for x in pattern.findall(content)] \n\n\nquestions = question_filter(three_splits)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:25:09.505812Z","iopub.execute_input":"2024-05-09T10:25:09.506183Z","iopub.status.idle":"2024-05-09T10:25:09.512296Z","shell.execute_reply.started":"2024-05-09T10:25:09.506156Z","shell.execute_reply":"2024-05-09T10:25:09.5113Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:47:40.036623Z","iopub.execute_input":"2024-05-09T10:47:40.037349Z","iopub.status.idle":"2024-05-09T10:47:52.97667Z","shell.execute_reply.started":"2024-05-09T10:47:40.037312Z","shell.execute_reply":"2024-05-09T10:47:52.975655Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.22.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain_community.embeddings import HuggingFaceEmbeddings \nfrom langchain.vectorstores.faiss import FAISS \n\nembeddings_checkpoint = \"sentence-transformers/all-MiniLM-L6-v2\"\nembeddings = HuggingFaceEmbeddings(model_name=embeddings_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:05:17.563649Z","iopub.execute_input":"2024-05-09T11:05:17.564032Z","iopub.status.idle":"2024-05-09T11:05:18.150201Z","shell.execute_reply.started":"2024-05-09T11:05:17.564004Z","shell.execute_reply":"2024-05-09T11:05:18.149175Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"store = FAISS.from_documents(answers, embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T11:05:21.301254Z","iopub.execute_input":"2024-05-09T11:05:21.30202Z","iopub.status.idle":"2024-05-09T11:05:21.572396Z","shell.execute_reply.started":"2024-05-09T11:05:21.30198Z","shell.execute_reply":"2024-05-09T11:05:21.571521Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"from langchain.chains import RetrievalQA\n\ndef make_qna(questions): \n    contexts = []\n    qa_chain = RetrievalQA.from_llm(llm=llm, retriever=store.as_retriever())\n    for ques in questions:\n        qa = qa_chain.run(ques)\n        contexts.append({\n            \"question\": ques, \n            \"answer\": qa, \n        })\n    return contexts\n\nstart = time.time()\nanswers = make_qna(questions)\npassed = time.time() - start\n\nminutes, seconds = divmod(passed, 60)\nprint(\"Time passed for generation: %d minutes %d seconds\" % (minutes, seconds))","metadata":{"execution":{"iopub.status.busy":"2024-05-09T12:09:05.959666Z","iopub.execute_input":"2024-05-09T12:09:05.960091Z","iopub.status.idle":"2024-05-09T12:12:14.452693Z","shell.execute_reply.started":"2024-05-09T12:09:05.96006Z","shell.execute_reply":"2024-05-09T12:12:14.451695Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Time passed for generation: 3 minutes 8 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"def filter_qna(answer): \n    qna = []\n    for ans in answer:\n        content = ans[\"answer\"]\n        pattern = re.compile(r\"\\d+\\. .*\\?+\\nHelpful Answer: .+\\.\")\n        qna.extend(pattern.findall(content)) \n    return qna \n\nqnas = filter_qna(answers)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T12:24:21.799193Z","iopub.execute_input":"2024-05-09T12:24:21.79956Z","iopub.status.idle":"2024-05-09T12:24:21.809636Z","shell.execute_reply.started":"2024-05-09T12:24:21.799531Z","shell.execute_reply":"2024-05-09T12:24:21.808554Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"for qna in qnas: \n    print(\"-\"*100)\n    print(qna)\n    print(\"-\"*100)\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T12:26:03.990883Z","iopub.execute_input":"2024-05-09T12:26:03.991595Z","iopub.status.idle":"2024-05-09T12:26:03.997581Z","shell.execute_reply.started":"2024-05-09T12:26:03.991562Z","shell.execute_reply":"2024-05-09T12:26:03.996585Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------------------------------------------\n1. What is the speaker's current job and how does it hurt them emotionally?\nHelpful Answer: The speaker's current job is now again a C++ developer. They find it emotionally bruising to return to active C++ dev after having worked in a more modern programming language with less legacy cruft. They feel the downsides of C++ sting more now.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n2. What are some features the speaker misses from Rust in C++?\nHelpful Answer: The speaker misses features like unique pointers and shared pointers, non-atomic pointers not being allowed to be passed between threads, and first class support for tuples in C++. They also find the syntax for enums less convenient.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n3. What does the speaker think about smart pointers in C++?\nHelpful Answer: The speaker thinks smart pointers are slower in C++ but acknowledges that the same can be said for C++ in general. They also mention that smart pointers make it easier to go longer with bad decisions, which they see as a good thing.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n4. What is the speaker's opinion on C++ being more difficult than other programming languages?\nHelpful Answer: The speaker does not agree with the idea that C++ difficulty is a sign of its power and that good programmers don't benefit from making things easier. They acknowledge that while they have the skills to navigate the paper cuts and foot guns of C++, they still slow them down and distract them from the actual problems they are trying to solve. They also believe that Rust's features make it easier to solve certain problems.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n5. What does the speaker think about Go being successful?\nHelpful Answer: The speaker suggests that Go is successful because it allows programmers to go longer with bad decisions than they can in Rust. They acknowledge that this is a parody, but have seen this attitude expressed many times. They do not agree with the idea that making things easier is a bad thing.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n2. What is the author's opinion on returning to active C++ development after having worked in a more modern programming language?\nHelpful Answer: The author finds returning to active C++ development to be exactly what they expected, but the downsides of C++ sting more now that they have worked in a more modern programming language with less legacy cruft. They miss features like enums, first class support for tuples, and smart pointers being faster. They also find that C++ creates unnecessary extra work and that some of its beginner-unfriendly features do not make the language more powerful. They prefer languages like Rust and Go that make it easier for beginners and have features that make development more convenient.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n3. What are some of the downsides of C++ that the author mentions in their blog post?\nHelpful Answer: The author mentions several downsides of C++ in their blog post, including the emotional pain of returning to active C++ development after working in a more modern programming language, missing features like first class support for tuples and enums, the slower performance of smart pointers, and the complexity of header files. They also express a desire for a programming language that is more beginner-friendly and easier to use.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n4. What are some features that the author misses from Rust while working in C++?\nHelpful Answer: The author misses several features from Rust while working in C++, including smart pointers, enums, and first-class support for tuples. They also find the syntax for using tuples in C++ to be less convenient and agree that smart pointers are slower in Rust as well. However, they acknowledge that these features come with trade-offs and that the choice between them ultimately depends on personal preference.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n5. How does the author view the defense that C++ is a great programming language for professionals?\nHelpful Answer: The author finds the argument that C++ is a great programming language for professionals because it's difficult and requires more skill to be baffling. They believe that this argument can also be made for languages like Rust, and that the idea that good programmers don't need help is a snooze fest. The author argues that experience with C++, while valuable, also comes with paper cuts and foot guns that slow them down and distract them from the actual problems they're trying to solve. They also believe that C++ creates unnecessary extra work, often due to decisions that made sense when they were made but no longer do. The author is not against Rust, but rather believes that people with excellent C++ backgrounds are the best Rust programmers because the thoughts about C++ can be transferred to Rust. The author also wants their programming language to be beginner-friendly and doesn't want to have to clean up mistakes of less skilled colleagues or earlier versions of themselves.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n6. What are the biggest paper cuts the author has noticed while returning to C++ development?\nHelpful Answer: The author has mentioned several paper cuts or annoyances they have encountered while returning to C++ development.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n7. What is the author's take on the default behavior of copyability in C++?\nHelpful Answer: The author expresses frustration with the default behavior of copyability in C++, stating that it can lead to bugs and that they often have to explicitly mark classes as non-copyable if they don't want the default copy constructor and assignment operator. They also mention that this can result in incorrect code being generated by the compiler if the programmer doesn't handle it correctly. The author also mentions that this issue is particularly problematic when using lambda functions and closures in C++11.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n8. Why does the author think that specifications of mutations are better than specifications of constants?\nHelpful Answer: The author believes that specifying mutations as opposed to specifying constants is a better trade-off because it makes the code more explicit and easier to understand. In C++, the default is for values to be mutable, and forgetting to mark a parameter or variable as const can lead to errors. By making mutations explicit, the compiler can remind developers when they are forgetting to mark something as mutable, which can help prevent bugs. The author also mentions that in languages like Rust and OCaml, the opposite default is used, where every value is implicitly constant unless explicitly declared mutable. This can help ensure that parameters and variables are used correctly based on whether the function or variable needs to be mutated or not. The author argues that this approach makes the code more explicit, easier to understand, and less prone to errors.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n9. What are the problems the author has with const in C++?\nHelpful Answer: The author has a problem with the fact that const is not the default in C++. They argue that specifying mutations as opposed to specifying constantness is a better trade-off. They also mention that forgetting to mark a parameter as const can lead to errors, and that many functions in the standard library had to be updated to take const iterator instead of iterator. The author also mentions that for functions like arrays, the collection is what should be mutable, not the iterator. They also mention that Rust and other languages have features like enums and first-class support for tuples that C++ could easily add, but don't. The author also mentions that smart pointers are slower in C++, but so is the alternative in Rust. The author also mentions that the argument that C++ is a great programming language because it's not beginner-friendly and that beginners just need to learn to appreciate it is a baffling take.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n10. What does the author mean by \"obligatory copying\" and why does it bother them?\nHelpful Answer: The author refers to \"obligatory copying\" as the requirement to make a copy of an object when passing it as a function argument or returning it from a function. This bothers the author because they believe that copying complicated data structures is a mistake, as it can lead to unnecessary memory allocations and performance issues. They argue that in many cases, the default copy constructor or copy assignment operator is sufficient, but when a custom implementation is needed, it can be time-consuming and error-prone. The author also mentions that in C++, there are several \"paper cuts\" or small annoyances that can slow down development and make the language less enjoyable to use. One of these paper cuts is the requirement for copying in certain situations, which the author finds particularly frustrating.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n11. What issues do the author have with out parameters in C++?\nHelpful Answer: The author has several issues with out parameters in C++. One issue is that the parameter looks the same as a value parameter at the call site, making it difficult to determine if the function is supposed to modify the parameter. Another issue is that the standard library expects the objects it manages to be copyable and will fail to compile if the closure object is move-only. The author also mentions that there is no ergonomic way to do a lambda capture by move in C++ 11, and this will be addressed in C++23. The author also mentions that the rule of five requires writing all copy constructors, copy assignment operators, and destructors, even though the compiler could make default implementations. The author also mentions that returning multiple values by tuple in C++ is long-winded and distracting, and C++ often resorts to out parameters as a result. The author also mentions that C++ has no way to deprecate core language features, making it difficult to transition the language to new syntax and clean up some of its issues. However, the author also mentions that Rust doesn't break backwards compatibility and is expanding exceptionally fast. The author also mentions that ignoring backwards compatibility in large existing code bases can make the programming language harder to use without making it more powerful or better.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n12. Why does the author prefer having the compiler be a smart pointer?\nHelpful Answer: The author prefers having the compiler be a smart pointer because it makes the code safer and easier to manage, even though it may be slower than manually managing memory with raw pointers. This is because the compiler can automatically handle tasks like memory deallocation and ensuring that there are no memory leaks or dangling pointers. This can save time and effort in the long run, even if there is a slight performance cost. Additionally, the author acknowledges that there are valid use cases for raw pointers, particularly in C APIs, but for many cases, the default implementations provided by the compiler are sufficient and should be relied upon.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n13. What is the rule of five in C++ and why is it a painful concept?\nHelpful Answer: The Rule of Five is a set of guidelines in C++ that can help prevent common pitfalls when dealing with copying and moving objects. It states that if a class needs to define any of the five special member functions (copy constructor, move constructor, copy assignment operator, move assignment operator, or destructor), it should define all of them or use a pre-existing implementation (such as the default generated ones or the ones provided by a base class). This is to ensure that the class's behavior is consistent and predictable when it comes to copying and moving objects. However, implementing all of these functions can be a painful and error-prone process, especially for large and complex classes. Additionally, the Rule of Five can lead to a lot of boilerplate code, which can make the class definition more verbose and harder to read. This is why many modern languages, such as Rust and Swift, provide more ergonomic ways to handle copying and moving objects, such as unique pointers and move semantics.\n----------------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------------\n14. What is the author's opinion on C++'s lack of a deprecation system and its impact on the language's design choices?\nHelpful Answer: The author expresses frustration with C++'s lack of a deprecation system, which they believe results in unnecessary complexity and makes it harder for programmers to avoid using outdated or error-prone constructs. They argue that this design choice slows down programmers and distracts them from solving the actual problems, and can make code less maintainable. The author also suggests that this lack of a deprecation system is not a sign of C++'s power, but rather a hindrance that can be partially obviated by better technology and language features.\n----------------------------------------------------------------------------------------------------\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}